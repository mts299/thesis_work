\subsection{Particle Swarm Optimization}
In 1995 Kennedy and Eberhart \cite{Kennedy1995} developed a stochastic algorithm known as Particle Swarm Optimization (PSO). This algorithm is a derivative-free population-based optimization method that has been further developed in the past recent years. The strategy of how this methods optimizes is based on the natural phenomena of flocking birds or a school of fish. The first iteration starts the particles at random positions, each particle will evaluate at the given positions and
report their resulting values back to the solver. Based on minimal or (maximal) value, the optimum particle will be labelled global best, $xgbest$, and the other particles will begin to swarm towards the global best particles region. Each particle is assigned a velocity vector during the evolution step of the algorithm that moves the particle to new position that is generally closer to the global best position. This movement calculation can be represented as:
\begin{equations}
    \label(PSO velocity)
    v^{k+1}_{i,j} = v^k_{i,j} + c_1r_1\big( xbest^k_{ij} - x^k_{i,j} \big) + c_2r_2(xgbest^k_j - x^k_{i,j}) \\
    x^{k+1}_{i,j} = x^k_{i,j} + v^{k+1}_{i,j} \\
\end{equations}
where $x^k_{i,j}$ and $v^k_{i,j}$ are the $j$th parameter of the $i$th particle's position and velocity vector in the $k$th iteration and $xbest^k_{i,j}$ is the best positions that ith particle has experienced. $r_1$ and $r_2$ are two random number between $(1,0)$ with $c_1$ and $c_2$ representing the particle's confidence in itself and the swarm. 

