\chapter{Background}
\label{background}

Global optimization is a method for finding global minima (or maxima) for convex and non-convex functions. Convex functions are defined as a function where any local minimum is the global minimum. Non-convex functions do not have this property and it is unknown which local minimum is the global minimum. Thus finding global minima for non-convex function is challenging. In the 1950's, exhaustive searches like the Simplex algorithm\cite{Liberti2000} were used to find global minima in a defined
domain for a non-convex function. However, this algorithm became obsolete as models became more complex and domains larger. In the most recent years two main types of global optimization solvers were developed to solve for the global minima of complex models, deterministic and stochastic. 
Deterministic algorithms guarantee finding the global minima by searching the whole
domain with tight convergence properties \cite{Pinter2002}. In 1969 the branch and bound algorithm \cite{Liberti2000} was one of the most well known algorithms for solving complex models like the travelling salesman problem \cite{Liberti2000}. However, this algorithm was restricted to specific types of problems like concave minimization and when computing worst case, its time complexity was exponential. With the need to solve problems in more reasonable amount of time. Stochastic
algorithms which uses adaptive random search, were developed in the seventies. 
By relying random search patters, stochastic algorithms are able to
obtain a good solution in a specified amount of time. These algorithms, unlike deterministic algorithms, cannot guarantee finding a global minimum. Because of this property of stochastic algorithms, further research has become popular in obtaining a better global minimum for different classifications of problems \cite{Aguiar,Pinter2002}. Various sub-categories of stochastic algorithms have appeared, like probabilistic approaches, Monte Carlo approaches, evolutionary algorithms \cite{Aguiar} and metaheuristics methods
\cite{Can2015}. Each sub-category target different problems
and shows various improvement on different type of functions. Some common well known algorithms include: particle swarm optimization (evolutionary algorithm), differential evolution (metaheuristic method), genetic algorithm (evolutionary algorithm), cross-entropy method (Monte-Carlo algorithm), and simulated annealing (probabilistic algorithm) \cite{Aguiar}.  

However, even with the multiple types of existing global optimization algorithms we are still faced with challenges depending on the properties that functions presents. One specific challenge that non-convex functions present is trapping the optimization algorithm in a local minimum that may not be the global minima leading to premature convergence. In certain algorithms like genetic algorithm, premature convergence is discouraged; this way the algorithm will try to explore as much of the
search space as possible. In other algorithms quenching is used that allows the solver to exploit the local minimum to obtain more information of the region. An example of an algorithm that quenches is Simulated Annealing \cite{Aguiar} where it may be desired by the user to obtain suboptimal minima.   

Other challenges which global optimization algorithms face depend on the programming of the model which may result in long computations, resource contention and/or failures in the code. Some software packages, like GAMS, LINDO, Excel PSP Solvers and LGO \cite{Pinter2002}, offer parallelization of the algorithms \cite{Liberti2000} to make the optimization process
faster, parameters for parallelization if resource contention is an issue, exception handle from the function and error logs for better understanding \cite{Pinter2002}. However, not every software package offers these solutions or may not implement the desired algorithm the user wishes to use. This are all limiting factors for the user wanting to optimize a model. 

For all the four challenges discussed so far in the Chapter, the user needs to pick a specific algorithm and software when optimizing a non-convex black box model that takes up computation resources. This is not always practical for the user, and sometimes the user is left with developing their own software to implement a specific algorithm to globally optimize the model. 

In this thesis these challenges are solved by applying software applications to desired algorithms for solving the applications discussed in Chapter~\ref{applications}. The two applications of this thesis use global optimization with the aid of the software applications Computefarm and the Optimization Database. 
Computefarm is a distributed systems software that distributes functions out to various underutilized computers, a process known as farming computers, to evaluate functions in parallel and report back to the global solver. This software addresses the challenge of function dependency of computationally long simulations and large resource consumption of the simulation. By doing so we avoid resource contention of running multiple simulations in parallel at the same time. Another feature of
computefarm is its robustness against failure; with the simulations evaluated on separate machines, when a machine failure occurs the simulation can be re-distributed to another farmed computer. This feature prevents the need to restart a simulation from beginning when a failure occurs. 

The Optimization Database is a reliable replacement for logging and displaying intermediate values of a global optimization. Because of the uncertainty that come when deciding which algorithm to use, users can consult the database as reference to determine if a different algorithm is needed or whether it is necessary to start another optimization of the current best result. Database are also useful in monitoring optimization for failures and having a back up storage of information of the
optimization. If the optimization proves to have obtained a global minimum from extensively long optimization, the database can be used as an intermediate storage for the data.  
These software applications are useful in global optimization and in facing the challenges encountered when optimizing black box models and used to solve the applications discussed in Chapter~\ref{applications}. 
