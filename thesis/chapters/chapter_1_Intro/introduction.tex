
\chapter{Introduction}
\label{introduction}

Optimization is a process to obtain a minimal (or maximal) result for a defined problem. Problems can be simple function like $f(x) = x^2$ to multiple functions that make up a complex model like determining the water saturation in a fuel cell. By optimizing these types of problems, known as objective functions, parameters for a given objective function is solved to minimize the result. Thus this can lead to new discoveries in research and push forward new technologies and ideas of understanding.
Optimization can be local or global. Local optimization searches in a given neighbourhood around a provided candidate solution. This obtains a local minimum value in the neighbourhood of the domain based on satisfying converging properties. In the case of searching for global minimum where the local minimum is not guaranteed to be a global minimum then a global solver is needed. A global optimization will search the whole domain unlike the local solver that searches a
neighbourhood of the domain. By doing this the global optimization process determines a global minimum in certain amount of time. There are two types of global optimization: deterministic and stochastic \cite{Liberti2000}. These types of global optimizations have found global solutions for the applications chemical equilibrium, nuclear reactors, curve fitting, vehicle design and cost \cite{Pinter2002}, and many others.

Deterministic algorithms guaranteed global a minimum however, take a large amount of time to do so because they search the whole domain. In the worst case, these algorithms have time complexities of exponential time. In the case where large amounts time is not practical, stochastic are then used. 

Stochastic algorithms cannot guarantee a global minimum because of the adaptive random searches they do. However, they can determine a good candidate minimum in a specified amount of time from the user. Researches tend to use these algorithms if the exact global minimum is not needed to solve for objective function. There are also various stochastic algorithms that may preform better on specific type objective functions. Some examples of algorithms are Particle Swarm
Optimization \cite{Kennedy}, Genetic Algorithm \cite{}, Simulated Annealing \cite{}. 

Various type of objective functions lead to various challenges for the global solver. One type of challenge is premature local convergence, this happens when a global solver gets stuck on exploring a local minimum. This wastes time on not finding a global minimum and can lead to longer optimization time for deterministic algorithms or not a good global candidate for stochastic algorithms. Objective functions that have the potential of premature local convergence is
non-convex functions where local minima are not guaranteed to be the global minimum. Thus a solver gets stuck in a local minimum making it difficult to find a global minimum value. Other challenges is when failure occurs in the objective function. The optimization process is challenged with graceful shutdown that may lead to  restarting from the beginning or re-evaluating the objective function in hopes a failure does not occur. A failure can occur when a
resource contention happens. Resource contention occurs when a parallel global optimization algorithms uses various resources (processors and memory) and the objective function also uses up resources. When multiple objective functions are running simultaneously that demand more resource power, contention occurs. Depending on the machine and the algorithms policy this can lead to serial optimization or a failure. If it is ran serially then this defeats the purpose of
speeding up the optimization process. In the latter case, the optimization process will needed to be restarted. Another challenge of global optimizations is when the objective function needs to be monitored to determine if further action is needed or obtain extra information. The monitoring aspect of an objective function is when the user has flexibility to change various properties of the function. This can change the sensitivity of the optimization process to
obtain a global minimum faster or slower. Other situations is when various external information is desired by the objective function that user may want to know
\begin{itemize}
  \item specific properties of the model, 
  \item post processing of data or
  \item knowing the top $N$ solutions.
\end{itemize}

My contributions to solving these challenges are the software Computefarm and the Optimization Database. Computefarm is a distributed system that utilizes unused computer resources on various client computers to run multiple function evaluations. As a result, it can speed up the iteration process of the given solver, and thereby speed up the search for the global
minimum in a black-box problem. It is also fault tolerant to failure of a farmed computer allowing the global optimization process to continue without needing to be restarted. 

The Optimization Database is a flexible database that allows the model or solver to store the result and extra information that may pertain to the simulation or post processing of the data. With this information the user can i) determine if the solver is stuck at a local minimum, ii) initiate other solvers based on currently stored data, or iii) use the data to further analyse the model. 

In this thesis we apply Computefarm and Optimization Database to two applications quantum error correction circuit design and crystal structure prediction.
In the first problem, a circuit is designed to correct for errors in quantum processor systems. Unlike transistor based computers, quantum computers cannot be controlled using a software-based design. Instead, they are controlled directly from a circuit component. This makes the process of manufacturing circuits and testing of desired reliability quite costly. In light of this, several models have been designed to simulate a quantum error correction circuit
to determine the effect of error correction on a given $n$-qubit system. To ensure high reliability, also known as feasibility, of the circuit design, the circuit parameters are optimized such that the model returns a desired feasibility. In this application the desired feasibility is $99.99\%$ for a encryption, decryption circuit \cite{Barends2014,Ghosh2013}. This is the highest modelled feasibility needed due to
external noise when manufactured. This feasibility value has been obtained for the $3$-qubit system \cite{Zahedinejad2014}. In this thesis, the $4$-qubit system is reached using global optimization algorithms and the software applications.   

Crystal structure prediction has been used in the past decade to approximate the most stable structure of a compound at a particular temperature and pressure environment. Because there is a large variety of lattice positions for a given compound, testing every possible lattice structure at a desired temperatures and pressures can be taxing. Thus researchers use Ab Initio structure codes to calculate properties of the given lattice in hopes of discovering a new structure for a given compound. One
particular property that Ab Initio codes return is the total energy of the provided lattice structure. This energy represents the stability of the structure in the given environment. The lower the energy, the more stable the structure and the potential of having interesting properties. For example, finding a structure harder than diamond seems impossible experimentally however, by globally optimizing a specific compound in a given environment a new stable structure can be discovered that may
be harder than diamond. Another region of interest for structure prediction is the development of crystals for electronics. This is because crystals have nice resonating frequencies and for this are used to build signal timing components in many devices like wrist watches and computer processor chips. Global optimization is needed to find the most stable structures for the
crystal compound to further determine properties like the optimal resonant frequency. In this thesis the diatomic structure of silicon dioxide is optimized to generate the most stable lattice structures of a quartz crystal to further understand the variations of each structure and their crystal properties. 

In this thesis, Chapter \ref{background} gives the background on global optimization algorithms and properties objective functions present to optimization process. In Chapter \ref{methods} documents the software developed, Computefarm and the Optimization Database. Chapter \ref{applications} describes the two applications, quantum error correction circuit design and crystal structure prediction of silicon dioxide and how the software was used to aid in
solving these problems. The final Chapter \ref{conclusion} summarizes the results obtained for the two applications and benefits the software had to solving the applications.

