
Quantum computers offer the promise of a spectral leap in performance for solving non-polynomial problems. Some examples of non-polynomial problems a quantum computer could solve are prime factoring, database searching and quantum simulations. Each problem requires a number qubits needed in a system to solve; prime factoring requires a three qubit system to factorize 15 but implementations have been made up to five-qubit systems\cite{Lucero}. Likewise quantum computers use logic gates to
solve steps in a
algorithm for these problems these operations can also require high number of qubit in a system. One operation that is focused on in the rest of this chapter is the encoding operation that requires a minimum of four qubits. A five-qubit system would take the next step and decode the encoded bit string. As operations and algorithms to solve non-polynomial problems using a quantum computer march forward higher number of qubit systems are needed to preform the needed operations to solve complex problems. However, with
this promise to solve non-polynomial problems comes the obligation of increased error correction to guarantee sufficient robustness to fault tolerance. When dealing with security and encryption error correction becomes the up-most importance to ensure information is reliable and secure.

In a qubit system errors occur by two ways: decoherence and machine error; decoherence is caused when environmental sub-atomic particles, photons or neutrinos, interact externally with the qubit system. This minor interaction over time dampens the qubit oscillatory pulse, losing all information given to the system. This error is included in the gate fidelity that is optimized experimentally, in the qubit optimization shown in this chapter we only look at the intrinsic fidelity. The intrinsic
fidelity only considers the
machine error because of it being easier to simulate in a computer program. Machine error is caused by optical measurements of the qubit system. Because qubits are sub-atomic particles they have quantum mechanical properties that allow them to be in both states at the same time. When a measurement is taken at a single state it is measured but a system can be given probabilities for the qubit system to favour a specific state. These probability coefficients are combinations that give the
qubit system the capability to take $2^N$ bits of information, where $N$ is the number of qubits. When the qubits are measured between states, several measurements are taken to get a mean state that the qubit system favours however, machine error can occur here. If not enough measurements are taken, or an optical sensor error occurs and misreads a state then the final mean state can be wrong. 

Therefore fault tolerance is needed in a qubit system to ensure the states that are measured are reliable for the given probabilities. This is also known as the stability of the qubit system and because of their entanglement property of creating superpositioned states, sensors have to have a high resolution to properly measure the $N$ potential states in a $N$-qubit system. One can imagine this makes the optimization more difficult to solve as the number of qubits increase to guarantee
the stability, thus the reason of quantum computer chips only using three-qubit systems. 

For a qubit system to be used in a processor chip a guaranteed intrinsic fidelity of $99.99\%$ needs to be promised in the error correction component. This value is lowest fidelity that has shown a strong enough stability for the system with correcting errors in gate fidelity, which is optimised experimentally. To ensure a high enough gate fidelity, the intrinsic fidelity is optimized in a simulation to find values of circuit parameters that reproduce $99.99\%$ for machine errors, then
tests are ran on the circuit design to obtain the overall best gate fidelity. Because the three qubit processor chip has been manufactured and has been optimized to meet the required intrinsic fidelity, the four qubit system is now the next system to be optimized. 

The four-qubit system is an essential step in security as it will be used in creating an encoding gate. Because encoding is a form of encryption that potentially can be stronger than standard techniques used by a transistor computers it is strongly desired in security and quantum networks. The problem is with out a five-qubit system to decode the message without human knowledge, minimal errors cans be made such that human can decode with out too much time for testing. This drives to
optimize the error correction circuit in the single-shot Tofoli gate, the primary gate used for measuring qubit states with minimal amount of machine error. Therefore when errors are observed the error correction circuit is used as a fault tolerance guard when the superior processor circuit fails.     

